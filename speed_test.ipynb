{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import cupy as cp\n",
    "from cucim.skimage import measure as cucim_measure\n",
    "from skimage import measure\n",
    "\n",
    "import cc3d\n",
    "\n",
    "from cc3d_gpu import gpu_connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the connected components equal?\n",
      "Matrix1 torch & cc3d: True\n",
      "Matrix2 torch & cc3d: True\n",
      "Matrix1 skimage & torch: True\n",
      "Matrix2 skimage & torch: True\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "# Matrix creation code remains the same\n",
    "matrix1_numpy = np.zeros((10, 35, 35))\n",
    "matrix1_numpy[0, 10:20, 10:20] = 1\n",
    "matrix1_numpy[0, 25:28, 10:20] = 1\n",
    "matrix1_numpy[0, 10:20, 21:30] = 1\n",
    "matrix1_numpy[0, 5:7, 5:7] = 1\n",
    "\n",
    "matrix2_numpy = np.zeros((10, 35, 35))\n",
    "matrix2_numpy[0, 10:20, 6:14] = 1\n",
    "matrix2_numpy[0, 10:20, 15:24] = 1\n",
    "matrix2_numpy[0, 25:28, 6:14] = 1\n",
    "matrix2_numpy[0, 25:28, 15:24] = 1\n",
    "matrix2_numpy[0, 25:27, 25:27] = 1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "matrix1_torch = torch.as_tensor(matrix1_numpy, dtype=torch.float32).to(device)\n",
    "matrix2_torch = torch.as_tensor(matrix2_numpy, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define functions to time\n",
    "def cc3d_cc():\n",
    "    matrix1_cc3d = cc3d.connected_components(matrix1_numpy)\n",
    "    matrix2_cc3d = cc3d.connected_components(matrix2_numpy)\n",
    "    return matrix1_cc3d, matrix2_cc3d\n",
    "\n",
    "def torch_cc():\n",
    "    matrix1_cc_torch, _ = gpu_connected_components(matrix1_torch)\n",
    "    matrix2_cc_torch, _ = gpu_connected_components(matrix2_torch)\n",
    "    torch.cuda.synchronize()  # Ensure CUDA operations are completed\n",
    "    return matrix1_cc_torch, matrix2_cc_torch\n",
    "\n",
    "def skimage_cc():\n",
    "    matrix1_skimage = measure.label(matrix1_numpy)\n",
    "    matrix2_skimage = measure.label(matrix2_numpy)\n",
    "    return matrix1_skimage, matrix2_skimage\n",
    "\n",
    "# Time the functions\n",
    "cc3d_time = timeit(cc3d_cc, number=100)\n",
    "torch_time = timeit(torch_cc, number=100)\n",
    "skimage_cc_time = timeit(skimage_cc, number=100)\n",
    "\n",
    "# Run once to get results for comparison\n",
    "matrix1_cc3d, matrix2_cc3d = cc3d_cc()\n",
    "matrix1_cc_torch, matrix2_cc_torch = torch_cc()\n",
    "matrix1_skimage, matrix2_skimage = skimage_cc()\n",
    "\n",
    "print('Are the connected components equal?')\n",
    "print('Matrix1 torch & cc3d:', np.allclose(matrix1_cc_torch.cpu().numpy(), matrix1_cc3d))\n",
    "print('Matrix2 torch & cc3d:', np.allclose(matrix2_cc_torch.cpu().numpy(), matrix2_cc3d))\n",
    "print('Matrix1 skimage & torch:', np.allclose(matrix1_skimage, matrix1_cc_torch.cpu().numpy()))\n",
    "print('Matrix2 skimage & torch:', np.allclose(matrix2_skimage, matrix2_cc_torch.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m torch_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: torch_cc(matrix_torch), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Torch\u001b[39;00m\n\u001b[1;32m     43\u001b[0m torch_nosync_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: torch_cc_nosync(matrix_torch), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Torch\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m numpy_time \u001b[38;5;241m=\u001b[39m \u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy_cc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Numpy\u001b[39;00m\n\u001b[1;32m     45\u001b[0m cc3d_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: cc3d_cc(matrix), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#CPU | Numpy\u001b[39;00m\n\u001b[1;32m     46\u001b[0m skimage_cc_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: skimage_cc(matrix), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#CPU | Numpy\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cucim/lib/python3.8/timeit.py:233\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeit\u001b[39m(stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, timer\u001b[38;5;241m=\u001b[39mdefault_timer,\n\u001b[1;32m    231\u001b[0m            number\u001b[38;5;241m=\u001b[39mdefault_number, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cucim/lib/python3.8/timeit.py:177\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m torch_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: torch_cc(matrix_torch), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Torch\u001b[39;00m\n\u001b[1;32m     43\u001b[0m torch_nosync_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: torch_cc_nosync(matrix_torch), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Torch\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m numpy_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mnumpy_cc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m, number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#GPU | Numpy\u001b[39;00m\n\u001b[1;32m     45\u001b[0m cc3d_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: cc3d_cc(matrix), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#CPU | Numpy\u001b[39;00m\n\u001b[1;32m     46\u001b[0m skimage_cc_time \u001b[38;5;241m=\u001b[39m timeit(\u001b[38;5;28;01mlambda\u001b[39;00m: skimage_cc(matrix), number\u001b[38;5;241m=\u001b[39mruns) \u001b[38;5;241m/\u001b[39m runs \u001b[38;5;66;03m#CPU | Numpy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mnumpy_cc\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy_cc\u001b[39m(matrix):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgpu_connected_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GPU-Connected-Components/cc3d_gpu.py:10\u001b[0m, in \u001b[0;36mgpu_connected_components\u001b[0;34m(img, connectivity)\u001b[0m\n\u001b[1;32m      8\u001b[0m img_cupy \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39masarray(img)\n\u001b[1;32m      9\u001b[0m labeled_img, num_features \u001b[38;5;241m=\u001b[39m cucim_measure\u001b[38;5;241m.\u001b[39mlabel(img_cupy, connectivity\u001b[38;5;241m=\u001b[39mconnectivity, return_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m labeled_img_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(labeled_img, device\u001b[38;5;241m=\u001b[39m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labeled_img_torch, num_features\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def create_matrix(size):\n",
    "    matrix = np.zeros((50, size, size))\n",
    "    matrix[0, size//4:size//2, size//4:size//2] = 1\n",
    "    matrix[0, 3*size//4:7*size//8, size//4:size//2] = 1\n",
    "    matrix[0, size//4:size//2, 5*size//8:3*size//4] = 1\n",
    "    return matrix\n",
    "\n",
    "def torch_cc(matrix):\n",
    "    result = gpu_connected_components(matrix)\n",
    "    torch.cuda.synchronize()\n",
    "    return result\n",
    "\n",
    "def torch_cc_nosync(matrix):\n",
    "    return gpu_connected_components(matrix)\n",
    "\n",
    "def cc3d_cc(matrix):\n",
    "    return cc3d.connected_components(matrix)\n",
    "\n",
    "def skimage_cc(matrix):\n",
    "    return measure.label(matrix)\n",
    "\n",
    "def numpy_cc(matrix):\n",
    "    return gpu_connected_components(matrix)\n",
    "\n",
    "sizes = [32, 64, 128, 256, 512, 1024, 1200]\n",
    "numpy_times = []\n",
    "torch_times = []\n",
    "torch_nosync_times = []\n",
    "cc3d_times = []\n",
    "skimage_cc_times = []\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for size in sizes:\n",
    "    matrix = create_matrix(size)\n",
    "    matrix_torch = torch.as_tensor(matrix, dtype=torch.float32).to(device)\n",
    "    \n",
    "    torch_time = timeit(lambda: torch_cc(matrix_torch), number=runs) / runs #GPU | Torch\n",
    "    torch_nosync_time = timeit(lambda: torch_cc_nosync(matrix_torch), number=runs) / runs #GPU | Torch\n",
    "    numpy_time = timeit(lambda: numpy_cc(matrix), number=runs) / runs #GPU | Numpy\n",
    "    cc3d_time = timeit(lambda: cc3d_cc(matrix), number=runs) / runs #CPU | Numpy\n",
    "    skimage_cc_time = timeit(lambda: skimage_cc(matrix), number=runs) / runs #CPU | Numpy\n",
    "    \n",
    "    torch_times.append(torch_time)\n",
    "    torch_nosync_times.append(torch_nosync_time)\n",
    "    cc3d_times.append(cc3d_time)\n",
    "    skimage_cc_times.append(skimage_cc_time)\n",
    "    numpy_times.append(numpy_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sizes, torch_times, marker='s', label='PyTorch')\n",
    "plt.plot(sizes, torch_nosync_times, marker='s', label='PyTorch (no sync)')\n",
    "plt.plot(sizes, cc3d_times, marker='^', label='cc3d')\n",
    "plt.plot(sizes, skimage_cc_times, marker='o', label='skimage')\n",
    "plt.plot(sizes, numpy_times, marker='x', label='Numpy')\n",
    "plt.title('Execution Time vs Matrix Size')\n",
    "plt.xlabel('Matrix Size')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.legend()\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.savefig('connected_components_comparison_line_graph.png')\n",
    "plt.show()\n",
    "\n",
    "# Create separate plots for each method\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(18, 6))\n",
    "\n",
    "ax1.plot(sizes, skimage_cc_times, marker='o', color='blue')\n",
    "ax1.set_title('Ski-image')\n",
    "ax1.set_xlabel('Matrix Size')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_xscale('log', base=2)\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(sizes, torch_times, marker='s', color='orange')\n",
    "ax2.set_title('PyTorch')\n",
    "ax2.set_xlabel('Matrix Size')\n",
    "ax2.set_ylabel('Time (seconds)')\n",
    "ax2.set_xscale('log', base=2)\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.plot(sizes, cc3d_times, marker='^', color='green')\n",
    "ax3.set_title('cc3d')\n",
    "ax3.set_xlabel('Matrix Size')\n",
    "ax3.set_ylabel('Time (seconds)')\n",
    "ax3.set_xscale('log', base=2)\n",
    "ax3.set_yscale('log')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax4.plot(sizes, numpy_times, marker='x', color='red')\n",
    "ax4.set_title('Numpy')\n",
    "ax4.set_xlabel('Matrix Size')\n",
    "ax4.set_ylabel('Time (seconds)')\n",
    "ax4.set_xscale('log', base=2)\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(True)\n",
    "\n",
    "ax5.plot(sizes, torch_nosync_times, marker='o', color='purple')\n",
    "ax5.set_title('PyTorch (no sync)')\n",
    "ax5.set_xlabel('Matrix Size')\n",
    "ax5.set_ylabel('Time (seconds)')\n",
    "ax5.set_xscale('log', base=2)\n",
    "ax5.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('connected_components_comparison_separate_plots.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cucim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
